mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
submit()
pack_sum
qunatile(pack_sum$count, probs = 0.99)
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count > 679)
top_counts
head(top_counts, 20)
arrange(top_counts, desc(count))
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
top_unique
arrange(top_unique, desc(unique))
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate(res, sex_class, c("sex", "class"))
submit()
students3
submit()
submit()
?gather
?spread
submit()
submit()
submit()
reset()
reset()
reset()
submit()
submit()
submit()
submit()
students3
students3
submit()
submit()
submit()
extract_numeric("class5")
submit()
students4
submit
submit()
submit()
submit()
passed
failed
passed <-mutate(passed, status = "passed")
failed <- mutate(failed, status = "failed")
rbind_list(passed, failed)
sat
submit()
submit()
submit()
submit()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = lubridate)
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label = TRUE)
this_moment <- now()
this_moment
hour(this_moment)
ymb("1989-05-17")
ymd("1989-05-17")
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("19-20-12")
ymd("1920-1-2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- now()
this_moment <- update(this_moment, hours = 10, minutes = 16, seconds = 0)
this_moment
?now
nyc <- now(tzone="America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive, "Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?new_interval
how_long <- new_interval(last_time, arrive)
as.period(how_long)
stopwatch()
clear()
cls()
quit()
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile = "../acs.csv")
acs <- read.csv("../acs.csv")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile = "../acs.csv")
acs <- read.csv("../acs.csv")
agricultureLogical <- acs[acs$ACR == 3 & acs$AGS ==6,]
str(acs)
?strsplit
chars <- strsplit(names(acs), "wgtp")
chars[123]
gdpUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(gdpUrl, destfile = "../gdp.csv")
eduUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(eduUrl, destfile = "../edu.csv")
gdp <- read.csv("../gdp.csv")
edu <- read.csv("../edu.csv")
str(gdp)
head(gdp)
gdp <- gdp[5:, ]
gdp <- gdp[5:330, ]
head(gdp)
gdp_num <- gdp$X.3
gdp_num
gdp_num <- as.numeric(gdp$X.3)
gdp_num
?gsub
gdp_num <- as.numeric(gsub(",",gdp$X.3))
gdp_num <- as.numeric(gsub(",", gdp$X.3))
gdp_num <- as.numeric(gsub(",", "", gdp$X.3))
?as.numeric
?mean
gdp_num
gdp_mean <- mean(gdp_num, na.rm=TRUE)
gdp <- read.csv("../gdp.csv")
edu <- read.csv("../edu.csv")
gdp_num <- as.numeric(gsub(",", "", gdp$X.3))
gdp_mean <- mean(gdp_num, na.rm=TRUE)
gdp
gdp <- gdp[5:219, ]
gdp_num <- as.numeric(gsub(",", "", gdp$X.3))
gdp_mean <- mean(gdp_num, na.rm=TRUE)
gdp
countryNames <- gdp$X.2
countryNames <- as.character(gdp$X.2)
grep("United$",countryNames)
grep("^United",countryNames)
grep("*United",countryNames)
gdp <- read.csv("../gdp.csv")
edu <- read.csv("../edu.csv")
mergedData = merge(gdp,edu,by.x="X",by.y="CountryCode",all=FALSE)
mergedData$Gross.domestic.product.2012 <- as.numeric(as.character(mergedData$Gross.domestic.product.2012))
str(mergedData)
mergedData$Special.Notes <- as.character(mergedData$Special.Notes)
str(mergedData)
?grep
grep("([Ff]iscal)&((June)|(june))", mergedData$Special.Notes)
grep("(June)|(june)", mergedData$Special.Notes)
grep("(Fiscal)|(fiscal)", grep("(June)|(june)", mergedData$Special.Notes))
grep("(June)|(june)", mergedData$Special.Notes)
count(grep("(June)|(june)", mergedData$Special.Notes))
length(grep("(June)|(june)", mergedData$Special.Notes))
length(grep("(Fiscal)&(June)", mergedData$Special.Notes))
length(grep("(Fiscal)", mergedData$Special.Notes))
length(grep("(Fiscal)*(June)", mergedData$Special.Notes))
install.packages("quantmod")
library(quantmod)
?which
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
str(amzn)
head(amzn)
sampleTimes
str(sampleTimes)
year(sampleTimes)
library(lubridate)
year(sampleTaimes)
year(sampleTimes)
length(year(sampleTimes) == 2012)
year(sampleTimes) == 2012)
year(sampleTimes) == 2012
?countif
library(lubridate)
years_2012 <- year(sampleTimes) == 2012
length(sampleTimes[which(years_2012)])
wday(sampleTimes)
wday(sampleTimes, label=TRUE)
years_2012_mon <- year(sampleTimes) == 2012 & wday(sampleTimes) == 2
length(sampleTimes[which(years_2012_mon)])
mergedData = merge(gdp,edu,by.x="X",by.y="CountryCode",all=FALSE)
mergedData$Gross.domestic.product.2012 <- as.numeric(as.character(mergedData$Gross.domestic.product.2012))
mergedData$Special.Notes <- as.character(mergedData$Special.Notes)
length(grep("^Fiscal*June", mergedData$Special.Notes))
length(grep("^Fiscal", mergedData$Special.Notes))
#5
length(grep("^Fiscal.June", mergedData$Special.Notes))
length(grep("Fiscal.June", mergedData$Special.Notes))
length(grep("^Fiscal.*June", mergedData$Special.Notes))
set.seed(1234)
par(mar = c(0,0,0,0))
x <- rnorm(12, mean = rep(1:3, each = 4), sd = 0.2)
y <- rnorm(12, mean = rep(c(1,2,1), each = 4), sd = 0.2)
plot(x, y, col="blue", pch= 19, cex = 2)
text(x + 0.05, y + 0.05, labels = as.character(1:12))
dataFrame <- data.frame(x = x, y = y)
dist(dataFrame)
?hclust
dataFrame <- data.frame(x = x, y = y)
dist(dataFrame) # Euclidean distance
distxy <- dist(dataFrame)
hClustering <- hclust(distxy)
plot(hClustering)
hClustering <- hclust(distxy)
par(mar = c(4,4,4,4))
plot(hClustering)
set.seed(143)
dataMatrix <- as.matrix(dataFrame)[sample(1:12),]
heatmap(dataMatrix)
set.seed(1234)
par(mar = c(0,0,0,0))
x <- rnorm(12, mean = rep(1:3, each = 4), sd = 0.2)
y <- rnorm(12, mean = rep(c(1,2,1), each = 4), sd = 0.2)
plot(x, y, col="blue", pch= 19, cex = 2)
text(x + 0.05, y + 0.05, labels = as.character(1:12))
set.seed(1234)
par(mar = c(0,0,0,0))
x <- rnorm(12, mean = rep(1:3, each = 4), sd = 0.2)
y <- rnorm(12, mean = rep(c(1,2,1), each = 4), sd = 0.2)
plot(x, y, col="blue", pch= 19, cex = 2)
text(x + 0.05, y + 0.05, labels = as.character(1:12))
dataFrame <- data.frame(x = x, y = y)
kmeansObj <- kmeans(dataFrame, centers=3)
names(kmeansObj)
kmeansObj$cluster
par(mar = rep(0.2, 4))
plot(x, y, col = kmeansOcj$cluster, pch= 19, cex = 2)
points(kmeansObject$centers, col= 1:3, pch = 3, lwd=3)
par(mar = rep(0.2, 4))
plot(x, y, col = kmeansObj$cluster, pch= 19, cex = 2)
points(kmeansObject$centers, col= 1:3, pch = 3, lwd=3)
points(kmeansObj$centers, col= 1:3, pch = 3, lwd=3)
set.seed(1234)
dataMatrix <- as.matrix(dataFrame)[sample(1:12),]
kmeansObj2 <- kmeans(dataFrame, centers=3)
par(mfrow = c(1,2), mar=c(2,4,0.1,0.1))
image(t(dataMatrix)[,nrow(dataMatrix):1], yaxt = "n")
image(t(dataMatrix)[,order(kmeansObj$cluster)], yaxt = "n")
set.seed(12345)
par(mar= rep(0.2,4))
dataMatrix <- matrix(rnorm(400), nrow=40)
image(1:10, 1:40, t(dataMatrix)[, nrow(dataMatrix):1])
heatmap(dataMatrix)
set.seed(678910)
for (i in 1:40)
{
# flip a coin
coinFlip <- rbinom(1, size=1, prob=0.5)
# if coin is heads add a common pattern to the row
if (coinFlip)
{
dataMatrix[i, ] <- dataMatrix[i,] + rep(c(0,3), each=5)
}
}
image(1:10, 1:40, t(dataMatrix)[, nrow(dataMatrix):1])
heatmap(dataMatrix)
hh <- hclust(dist(dataMatrix))
dataMatrixOrdered <- dataMatrix[hh$order,]
par(mfrow=c(1,3))
image(t(dataMatrixOrdered)[,nrow(dataMatrixOrdered):1])
plot(rowMeans(dataMatrixOrdered), 40:1,,xlab = "Row Mean", ylab="Row" pch=19)
plot(colMeans(dataMatrixOrdered), xlab = "Column", ylab="Column Mean" pch=19)
plot(rowMeans(dataMatrixOrdered), 40:1,,xlab = "Row Mean", ylab="Row", pch=19)
plot(colMeans(dataMatrixOrdered), xlab = "Column", ylab="Column Mean", pch=19)
par(mfrow=c(1,3), mar=c(4,4,4,4))
image(t(dataMatrixOrdered)[,nrow(dataMatrixOrdered):1])
plot(rowMeans(dataMatrixOrdered), 40:1,,xlab = "Row Mean", ylab="Row", pch=19)
plot(colMeans(dataMatrixOrdered), xlab = "Column", ylab="Column Mean", pch=19)
svd1 <- svd(scale(dataMatrixOrdered))
par(mfrow=c(1,3))
image(t(dataMatrixOrdered)[,nrow(dataMatrixOrdered):1])
plot(svd1$u[,1],40:1,,xlab="Row",ylab="First left Singular Vector", pch=19)
plot(svd1$v[,1],xlab="Column",ylab="First right Singular Vector", pch=19)
par(mfrow=c(1,2))
plot(svc1$d,xlab="Column", ylab="Singular Value", pch=19)
plot(svc1$d^2/sum(svd1$d^2),xlab="Column", ylab="Prop of variance explained, pch=19)
plot(svd1$d,xlab="Column", ylab="Singular Value", pch=19)
plot(svd1$d^2/sum(svd1$d^2),xlab="Column", ylab="Prop of variance explained, pch=19)
heatmap(dataMatrix)
par(mfrow=c(1,2))
plot(svd1$d, xlab="Column", ylab="Singular Value", pch=19)
plot(svd1$d^2/sum(svd1$d^2),xlab="Column", ylab="Prop of variance explained", pch=19)
par(mfrow=c(1,2))
plot(svd1$d, xlab="Column", ylab="Singular Value", pch=19)
plot(svd1$d^2/sum(svd1$d^2),xlab="Column", ylab="Prop of variance explained", pch=19)
pca1 <- prcomp(dataMatrixOrdered, scale=TRUE)
plot(pca1$rotation[,1], svd1$v[,1] pch=19, xlab="Principal Component", ylab="Right singular vector1")
abline(c(0,1))
pca1 <- prcomp(dataMatrixOrdered, scale=TRUE)
plot(pca1$rotation[,1], svd1$v[,1], xlab="Principal Component", ylab="Right singular vector1", pch=19)
abline(c(0,1))
constantMatrix <- dataMatrixOrdered*0
for(i in 1:dim(dataMatrixOrdered)[1]){constantMatrix[i,] <- rep(c(0,1) each=5)}
svd1 <- svd(constantMatrix)
par(mfrow=c(1,3))
image(t(constantMatrix)[,nrow(constantMatrix):1])
plot(svd1$u[,1],40:1,,xlab="Row",ylab="First left Singular Vector", pch=19)
plot(svd1$v[,1],xlab="Column",ylab="First right Singular Vector", pch=19)
constantMatrix <- dataMatrixOrdered*0
for(i in 1:dim(dataMatrixOrdered)[1])
{constantMatrix[i,] <- rep(c(0,1), each=5)}
svd1 <- svd(constantMatrix)
par(mfrow=c(1,3))
image(t(constantMatrix)[,nrow(constantMatrix):1])
plot(svd1$u[,1],40:1,,xlab="Row",ylab="First left Singular Vector", pch=19)
plot(svd1$v[,1],xlab="Column",ylab="First right Singular Vector", pch=19)
install.packages(kernlab)
install.packages("kernlab")
clear()
cls()
cl()
?clear
??clear
rm()
rm(*)
?rm
rm(ls())
rm(list=ls())
library(kernlab)
data(spam)
library(kernlab)
data(spam)
set.seed(3435)
trainIndicator = rbinom(4601, size = 1, prob=0.5)
table(trainIndication)
trainIndicator = rbinom(4601, size = 1, prob=0.5)
table(trainIndicator)
set.seed(3435)
trainIndicator = rbinom(4601, size = 1, prob=0.5)
table(trainIndicator)
trainSpam = spam[trainIndicator == 1,]
testSpam = spam[trainIndicator == 0,]
names(trainSpam)
head(trainSpam)
table(trainSpam$type)
plot(log10(trainSpam$capitalAve + 1) ~ trainSpam$type)
plot(log10(trainSpam$capitalAve + 1) ~ trainSpam$type)
hClusterUpdated = hclust(dist(t(log10(trainSpam[,1:55] +1))))
plot(hClusterUpdated)
library(boot)
trainSpam$numType = as.numeric(trainSpan$type) - 1
costFunction = function(x,y) sum(x != (y > 0.5))
cvError = rep(NA, 55)
library(boot)
for (i in 1:55)
{
lmFormula = reformulate(names(trainSpam)[i], response = "numType")
glmFit = glm(lmFormula, family="binomial", data=trainSpam)
cvError[i] = cv.glm(trainSpam, glmFit, costFunction, 2)$delta[2]
}
library(kernlab)
trainSpam$numType = as.numeric(trainSpam$type) - 1
costFunction = function(x,y) sum(x != (y > 0.5))
cvError = rep(NA, 55)
library(boot)
for (i in 1:55)
{
lmFormula = reformulate(names(trainSpam)[i], response = "numType")
glmFit = glm(lmFormula, family="binomial", data=trainSpam)
cvError[i] = cv.glm(trainSpam, glmFit, costFunction, 2)$delta[2]
}
names(trainSpam)[which.min(cvError)]
predictionModel = glm(numType ~ charDollar), family="binomial", data=trainSpam)
predictionTest = predict(predictionModel, testSpam)
predictedSpam = rep("nonspam", dim(testSpam)[1])
predictedSpam[predictionModel$fitted > 0.5] = "spam"
predictionModel = glm(numType ~ charDollar, family="binomial", data=trainSpam)
predictionTest = predict(predictionModel, testSpam)
predictedSpam = rep("nonspam", dim(testSpam)[1])
predictedSpam[predictionModel$fitted > 0.5] = "spam"
table(predictedSpam, testSpam$type)
setwd("E:\\Coursera\\Reproducible\\RepData_PeerAssessment1")
# Loading and preprocessing the data
#1
activity_df <- read.csv("activity.csv")
#2
library(data.table)
activity <- as.data.table(activity_df)]
activity$date <- as.Date(activity$date)
activity_by_date <- activity[,sum(steps,na.rm=TRUE), by=date]
setnames(activity_by_date, "V1", "total_steps")
activity_by_interval <- activity[,mean(steps,na.rm=TRUE), by=interval]
setnames(activity_by_interval, "V1", "average_steps")
## What is mean total number of steps taken per day?
#1
hist(activity_by_date$total_steps, xlab="Total Steps", main="Histogram of Total Steps per day")
#2
mean_steps <- mean(activity_by_date$total_steps, na.rm=TRUE)
median_steps <- median(activity_by_date$total_steps, na.rm=TRUE)
## What is the average daily activity pattern?
#1
plot(type="l", activity_by_interval$interval, activity_by_interval$average_steps)
#2
max_average_steps <- max(activity_by_interval$average_steps)
max_average_steps_interval <- subset(activity_by_interval, average_steps == max_average_steps)$interval
## Imputing missing values
#1
activity_clean <- merge(activity, activity_by_interval, by="interval")
nas <- which(is.na(activity_clean$steps))
total_nas <- length(nas)
#2
activity_clean$steps[is.na(activity_clean$steps)] <- activity_clean$average_steps[is.na(activity_clean$steps)]
#3
activity_clean <- activity_clean[,average_steps:=NULL]
#4
activity_clean_by_date <- activity_clean[,sum(steps,na.rm=TRUE), by=date]
setnames(activity_clean_by_date, "V1", "total_steps")
hist(activity_clean_by_date$total_steps, xlab="Total Steps", main="Histogram of Total Steps per day")
mean_clean_steps <- mean(activity_clean_by_date$total_steps)
median_clean_steps <- median(activity_clean_by_date$total_steps)
## Are there differences in activity patterns between weekdays and weekends?
library(ggplot2)
activity_df <- read.csv("activity.csv")
#2
library(data.table)
activity <- as.data.table(activity_df)
activity$date <- as.Date(activity$date)
activity_by_date <- activity[,sum(steps,na.rm=TRUE), by=date]
setnames(activity_by_date, "V1", "total_steps")
activity_by_interval <- activity[,mean(steps,na.rm=TRUE), by=interval]
setnames(activity_by_interval, "V1", "average_steps")
## What is mean total number of steps taken per day?
#1
hist(activity_by_date$total_steps, xlab="Total Steps", main="Histogram of Total Steps per day")
#2
mean_steps <- mean(activity_by_date$total_steps, na.rm=TRUE)
median_steps <- median(activity_by_date$total_steps, na.rm=TRUE)
## What is the average daily activity pattern?
#1
plot(type="l", activity_by_interval$interval, activity_by_interval$average_steps)
#2
max_average_steps <- max(activity_by_interval$average_steps)
max_average_steps_interval <- subset(activity_by_interval, average_steps == max_average_steps)$interval
## Imputing missing values
#1
activity_clean <- merge(activity, activity_by_interval, by="interval")
nas <- which(is.na(activity_clean$steps))
total_nas <- length(nas)
#2
activity_clean$steps[is.na(activity_clean$steps)] <- activity_clean$average_steps[is.na(activity_clean$steps)]
#3
activity_clean <- activity_clean[,average_steps:=NULL]
#4
activity_clean_by_date <- activity_clean[,sum(steps,na.rm=TRUE), by=date]
setnames(activity_clean_by_date, "V1", "total_steps")
hist(activity_clean_by_date$total_steps, xlab="Total Steps", main="Histogram of Total Steps per day")
mean_clean_steps <- mean(activity_clean_by_date$total_steps)
median_clean_steps <- median(activity_clean_by_date$total_steps)
## Are there differences in activity patterns between weekdays and weekends?
library(ggplot2)
library(ggplot2)
activity_clean <- as.data.frame(activity_clean)
activity_clean$weekday <- weekdays(activity_clean$date)
activity_clean$weekday <- gsub("Monday|Tuesday|Wednesday|Thursday|Friday", "Weekday", activity_clean$weekday)
activity_clean$weekday <- gsub("Saturday|Sunday", "Weekend", activity_clean$weekday)
activity_clean$weekday <- as.factor(activity_clean$weekday)
activity_clean_grouped <- aggregate(activity_clean$steps, by=list(Weekday = activity_clean$weekday, Interval = activity_clean$interval), FUN = mean)
plot <- ggplot(data = activity_clean_grouped, aes(Interval, x, group=1))
plot + geom_line()
plot <- ggplot(data = activity_clean_grouped, aes(Interval, x, group=1))
plot + geom_line() + facet_grid(.~Weekday)
plot <- ggplot(data = activity_clean_grouped, aes(Interval, x, group=1))
plot + geom_line() + facet_grid(.~Weekday) + labs(title = "Average Steps per Inteval by Weekday/Weekend", xlab = "Average number of steps")
plot <- ggplot(data = activity_clean_grouped, aes(Interval, x, group=1))
plot + geom_line() + facet_grid(.~Weekday) + labs(title = "Average Steps per Interval by Weekday/Weekend", y = "Average number of steps")
library(data.table)
activity_df <- read.csv("activity.csv")
activity <- as.data.table(activity_df)
hist(activity[,sum(steps,na.rm=TRUE), by=date]$V1, xlab="Total Steps", main="Histogram of Total Steps per day")
knit2html("PA1_template.Rmd")
library(knitr)
knit2html("PA1_template.Rmd")
knit2html("PA1_template.Rmd")
